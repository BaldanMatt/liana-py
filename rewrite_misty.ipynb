{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "from scipy.sparse import identity, issparse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "\n",
    "from liana.method.sp._spatial_pipe import spatial_neighbors\n",
    "from liana.method.sp._misty import _get_neighbors\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from mudata import MuData\n",
    "from anndata import AnnData\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydata = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = sc.read_h5ad('liana/tests/data/synthetic.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ydata = ydata if ydata else xdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liana.method._pipe_utils import prep_check_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liana.mt.sp._misty import _check_target_in_predictors, _check_features, _single_view_model, _mask_connectivity, _multi_model, _format_targets, _format_importances, _concat_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "juxta_cutoff = np.inf\n",
    "set_diag = True\n",
    "spatial_key = 'spatial'\n",
    "bandwidth = 10\n",
    "kernel = 'misty_rbf'\n",
    "zoi = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _check_anndata_objects_groups(xdata,\n",
    "#                               ydata,\n",
    "#                               spatial_key=spatial_key,\n",
    "#                               group_intra_by=group_intra_by,\n",
    "#                               group_env_by=group_env_by\n",
    "#                               )\n",
    "\n",
    "# predictors = _check_features(xdata, predictors, type_str=\"predictors\")\n",
    "# targets = _check_features(ydata, targets, type_str=\"targets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_view(adata, connecitivity=None, spatial_key=None, layer=None, use_raw=False):\n",
    "    adata = prep_check_adata(adata, use_raw=use_raw, layer=layer, groupby=None, min_cells=None)    \n",
    "    if connecitivity is not None:\n",
    "        conns = connecitivity\n",
    "        obsp = {'spatial_connectivities': conns}\n",
    "    elif spatial_key is not None:\n",
    "        conns = adata.obsp[spatial_key]\n",
    "        obsp = {'spatial_connectivities': conns}\n",
    "    else:\n",
    "        obsp=None\n",
    "        \n",
    "    return AnnData(adata.X, obs=adata.obs, obsp=obsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # validate inputs \n",
    "# if not overwrite and (\"misty_results\" in mdata.uns.keys()) and inplace:\n",
    "#     raise ValueError(\"mdata already contains misty results. Set overwrite=True to overwrite.\")\n",
    "# if x_mod not in mdata.mod.keys():\n",
    "#     raise ValueError(f\"Predictor modality {x_mod} not found in mdata.\")\n",
    "# if y_mod is not None and y_mod not in mdata.mod.keys():\n",
    "#     raise ValueError(f\"Target modality {y_mod} not found in mdata.\")\n",
    "# if add_para and bandwidth is None:\n",
    "#     raise ValueError(\"bandwith must be specified if add_para=True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "intra = _make_view(adata=ydata, use_raw=False, layer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = _get_neighbors(adata=xdata,\n",
    "                           juxta_cutoff=juxta_cutoff,\n",
    "                           set_diag=set_diag, \n",
    "                           spatial_key=spatial_key\n",
    "                           )\n",
    "\n",
    "juxta = _make_view(xdata, use_raw=False, layer=None, connecitivity=neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = spatial_neighbors(adata=xdata,\n",
    "                            bandwidth=bandwidth, \n",
    "                            kernel=kernel,\n",
    "                            set_diag=set_diag, \n",
    "                            inplace=False,\n",
    "                            cutoff=0,\n",
    "                            zoi=zoi\n",
    "                            )\n",
    "para = _make_view(xdata, use_raw=False, layer=None, connecitivity=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbdimitrov/anaconda3/envs/liana-py/lib/python3.10/site-packages/mudata/_core/mudata.py:457: UserWarning: Cannot join columns with the same name because var_names are intersecting.\n"
     ]
    }
   ],
   "source": [
    "views = MuData({'intra':intra, 'juxta':juxta, 'para':para})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['intra', 'juxta', 'para'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views.mod.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: two applications\n",
    "# juxta, para\n",
    "# misty_lr\n",
    "# anything else would require a new constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FIT params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100\n",
    "n_jobs = -1\n",
    "seed = 1337\n",
    "bypass_intra = True\n",
    "keep_same_predictor = False\n",
    "k_cv = 10\n",
    "alphas = [0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_intra_by = None\n",
    "group_env_by = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = None\n",
    "targets = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO are to be moved when constructing the views\n",
    "predictors = _check_features(xdata, predictors, type_str=\"predictors\")\n",
    "targets = _check_features(ydata, targets, type_str=\"targets\")\n",
    "\n",
    "intra_groups = np.unique(ydata.obs[group_intra_by]) if group_intra_by else [None]\n",
    "env_groups = np.unique(xdata.obs[group_env_by]) if group_env_by else [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_str = list(views.mod.keys())\n",
    "if bypass_intra:\n",
    "    view_str.remove('intra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init list to store the results for each intra group and env group as dataframe;\n",
    "targets_list, importances_list = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each target and build one RF model for each view\n",
    "for target in targets:\n",
    "    \n",
    "    for intra_group in intra_groups:\n",
    "        intra_obs_msk = ydata.obs[group_intra_by] == \\\n",
    "                intra_group if intra_group else np.ones(ydata.shape[0], dtype=bool)\n",
    "        \n",
    "        if issparse(ydata.X):\n",
    "            y = np.asarray(ydata[intra_obs_msk, target].X.todense()).reshape(-1)\n",
    "        else:\n",
    "            y = ydata[intra_obs_msk, target].X.reshape(-1)\n",
    "\n",
    "        # intra is always non-self, while other views can be self\n",
    "        predictors_nonself, insert_index = _check_target_in_predictors(target, predictors)\n",
    "        preds = predictors if keep_same_predictor else predictors_nonself\n",
    "\n",
    "        importance_dict = {}\n",
    "        \n",
    "        # model the intraview\n",
    "        if not bypass_intra:\n",
    "            oob_predictions_intra, importance_dict[\"intra\"] = _single_view_model(y,\n",
    "                                                                                 ydata,\n",
    "                                                                                 intra_obs_msk, \n",
    "                                                                                 predictors_nonself, \n",
    "                                                                                 n_estimators, \n",
    "                                                                                 n_jobs, \n",
    "                                                                                 seed\n",
    "                                                                                 )\n",
    "            if insert_index is not None and keep_same_predictor:\n",
    "                importance_dict[\"intra\"] = np.insert(importance_dict[\"intra\"], insert_index, np.nan)\n",
    "\n",
    "        # loop over the group_views_by\n",
    "        for env_group in env_groups:\n",
    "            # store the oob predictions for each view to construct predictor matrix for meta model\n",
    "            oob_list = []\n",
    "            \n",
    "            env_obs_msk = ydata.obs[group_env_by] == env_group if env_group else np.ones(xdata.shape[0], dtype=bool)\n",
    "\n",
    "            if not bypass_intra:\n",
    "                oob_list.append(oob_predictions_intra)\n",
    "\n",
    "            # model the juxta and paraview (if applicable)\n",
    "            ## TODO: remove this thing with all\n",
    "            for view_name in [v for v in view_str if v != \"intra\"]:\n",
    "                connectivity = views.mod[view_name].obsp[\"spatial_connectivities\"]\n",
    "                # NOTE indexing here is expensive, but we do it to avoid memory issues\n",
    "                view = _mask_connectivity(xdata, connectivity, env_obs_msk, predictors)\n",
    "                \n",
    "                oob_predictions, importance_dict[view_name] = \\\n",
    "                    _single_view_model(y,\n",
    "                                    view, \n",
    "                                    intra_obs_msk, \n",
    "                                    preds, \n",
    "                                    n_estimators,\n",
    "                                    n_jobs,\n",
    "                                    seed\n",
    "                                    )\n",
    "                oob_list.append(oob_predictions)\n",
    "\n",
    "\n",
    "            # train the meta model with k-fold CV \n",
    "            intra_r2, multi_r2, coefs = _multi_model(y,\n",
    "                                                    np.column_stack(oob_list),\n",
    "                                                    intra_group, \n",
    "                                                    bypass_intra, \n",
    "                                                    view_str, \n",
    "                                                    k_cv, \n",
    "                                                    alphas, \n",
    "                                                    seed\n",
    "                                                    )\n",
    "            \n",
    "            targets_df = _format_targets(target,\n",
    "                                        intra_group,\n",
    "                                        env_group,\n",
    "                                        view_str,\n",
    "                                        intra_r2,\n",
    "                                        multi_r2,\n",
    "                                        coefs\n",
    "                                        )\n",
    "            targets_list.append(targets_df)\n",
    "            \n",
    "            importances_df = _format_importances(target, \n",
    "                                                preds, \n",
    "                                                intra_group, \n",
    "                                                env_group,\n",
    "                                                importance_dict\n",
    "                                                )\n",
    "            importances_list.append(importances_df)\n",
    "\n",
    "\n",
    "# create result dataframes\n",
    "target_metrics, importances = _concat_dataframes(targets_list,\n",
    "                                                importances_list,\n",
    "                                                view_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MistyConstructor():\n",
    "    def __init__(self, views):\n",
    "        self.views = views\n",
    "        self.view_names = views.mod.keys()\n",
    "        self._check_views()\n",
    "        \n",
    "    def _get_view(self, view_name):\n",
    "        return self.views.mod[view_name]\n",
    "    \n",
    "    def _get_view_names(self):\n",
    "        return self.view_names\n",
    "    \n",
    "    def _check_views(self):\n",
    "        views = self.views\n",
    "        assert isinstance(views, MuData), \"views must be a MuData object\"\n",
    "        \n",
    "        for view in self.view_names:\n",
    "            if \"spatial_connectivities\" not in views.mod[view].obsp.keys():\n",
    "                raise ValueError(f\"view {view} must contain a spatial_connectivities key in .obsp\")\n",
    "            \n",
    "    def _get_connectivity(self, view_name):\n",
    "        return self._get_view(view_name).obsp[\"spatial_connectivities\"]\n",
    "    \n",
    "    def _get_X(self, view_name):\n",
    "        return self._get_view(view_name).X\n",
    "    \n",
    "    def __call__(self,\n",
    "                 adata,\n",
    "                 targets = None,\n",
    "                 predictors = None,\n",
    "                 keep_same_predictor = False,  # TODO: maybe rename this variable\n",
    "                 spatial_key = \"spatial\", \n",
    "                 add_juxta = True,\n",
    "                 add_para = True,\n",
    "                 bypass_intra = False,\n",
    "                 group_intra_by = None,\n",
    "                 group_env_by = None,\n",
    "                 alphas = [0.1, 1, 10],\n",
    "                 k_cv = 10,\n",
    "                 n_estimators = 100,\n",
    "                 n_jobs = -1,\n",
    "                 seed = 1337,\n",
    "                 inplace = True,\n",
    "                 ):\n",
    "        \n",
    "\n",
    "        intra_groups = np.unique(ydata.obs[group_intra_by]) if group_intra_by else [None]\n",
    "        env_groups = np.unique(xdata.obs[group_env_by]) if group_env_by else [None]\n",
    "\n",
    "        connectivities = {}\n",
    "        if add_juxta:\n",
    "            connectivities['juxta'] = _get_neighbors(xdata,\n",
    "                                                     juxta_cutoff=juxta_cutoff,\n",
    "                                                     set_diag=set_diag, \n",
    "                                                     spatial_key=spatial_key\n",
    "                                                     )\n",
    "        if add_para:\n",
    "            connectivities['para'] = spatial_neighbors(adata=xdata,\n",
    "                                                    bandwidth=bandwidth, \n",
    "                                                    kernel=kernel,\n",
    "                                                    set_diag=set_diag, \n",
    "                                                    inplace=False,\n",
    "                                                    cutoff=0,\n",
    "                                                    zoi=zoi\n",
    "                                                    )\n",
    "        view_str = list(connectivities.keys())\n",
    "        if not bypass_intra:\n",
    "            view_str = ['intra'] + view_str\n",
    "\n",
    "        # init list to store the results for each intra group and env group as dataframe;\n",
    "        targets_list, importances_list = [], []\n",
    "\n",
    "        # loop over each target and build one RF model for each view\n",
    "        for target in targets:\n",
    "            \n",
    "            for intra_group in intra_groups:\n",
    "                intra_obs_msk = ydata.obs[group_intra_by] == \\\n",
    "                        intra_group if intra_group else np.ones(ydata.shape[0], dtype=bool)\n",
    "                \n",
    "                if issparse(ydata.X):\n",
    "                    y = np.asarray(ydata[intra_obs_msk, target].X.todense()).reshape(-1)\n",
    "                else:\n",
    "                    y = ydata[intra_obs_msk, target].X.reshape(-1)\n",
    "\n",
    "                # intra is always non-self, while other views can be self\n",
    "                predictors_nonself, insert_index = _check_target_in_predictors(target, predictors)\n",
    "                preds = predictors if keep_same_predictor else predictors_nonself\n",
    "\n",
    "                importance_dict = {}\n",
    "                \n",
    "                # model the intraview\n",
    "                if not bypass_intra:\n",
    "                    oob_predictions_intra, importance_dict[\"intra\"] = _single_view_model(y,\n",
    "                                                                                         ydata, \n",
    "                                                                                         intra_obs_msk, \n",
    "                                                                                         predictors_nonself, \n",
    "                                                                                         n_estimators, \n",
    "                                                                                         n_jobs, \n",
    "                                                                                         seed\n",
    "                                                                                         )\n",
    "                    if insert_index is not None and keep_same_predictor:\n",
    "                        importance_dict[\"intra\"] = np.insert(importance_dict[\"intra\"], insert_index, np.nan)\n",
    "\n",
    "                # loop over the group_views_by\n",
    "                for env_group in env_groups:\n",
    "                    # store the oob predictions for each view to construct predictor matrix for meta model\n",
    "                    oob_list = []\n",
    "                    \n",
    "                    env_obs_msk = ydata.obs[group_env_by] == env_group if env_group else np.ones(xdata.shape[0], dtype=bool)\n",
    "\n",
    "                    if not bypass_intra:\n",
    "                        oob_list.append(oob_predictions_intra)\n",
    "\n",
    "                    # model the juxta and paraview (if applicable)\n",
    "                    ## TODO: remove this thing with all\n",
    "                    for view_name in [v for v in view_str if v != \"intra\"]:\n",
    "                        connectivity = connectivities[view_name]\n",
    "                        # NOTE indexing here is expensive, but we do it to avoid memory issues\n",
    "                        view = _mask_connectivity(xdata, connectivity, env_obs_msk, predictors)\n",
    "                        \n",
    "                        oob_predictions, importance_dict[view_name] = \\\n",
    "                            _single_view_model(y,\n",
    "                                            view, \n",
    "                                            intra_obs_msk, \n",
    "                                            preds, \n",
    "                                            n_estimators,\n",
    "                                            n_jobs,\n",
    "                                            seed\n",
    "                                            )\n",
    "                        oob_list.append(oob_predictions)\n",
    "\n",
    "\n",
    "                    # train the meta model with k-fold CV \n",
    "                    intra_r2, multi_r2, coefs = _multi_model(y,\n",
    "                                                            np.column_stack(oob_list),\n",
    "                                                            intra_group, \n",
    "                                                            bypass_intra, \n",
    "                                                            view_str, \n",
    "                                                            k_cv, \n",
    "                                                            alphas, \n",
    "                                                            seed\n",
    "                                                            )\n",
    "                    \n",
    "                    targets_df = _format_targets(target,\n",
    "                                                intra_group,\n",
    "                                                env_group,\n",
    "                                                view_str,\n",
    "                                                intra_r2,\n",
    "                                                multi_r2,\n",
    "                                                coefs\n",
    "                                                )\n",
    "                    targets_list.append(targets_df)\n",
    "                    \n",
    "                    importances_df = _format_importances(target, \n",
    "                                                        preds, \n",
    "                                                        intra_group, \n",
    "                                                        env_group,\n",
    "                                                        importance_dict\n",
    "                                                        )\n",
    "                    importances_list.append(importances_df)\n",
    "\n",
    "\n",
    "        # create result dataframes\n",
    "        target_metrics, importances = _concat_dataframes(targets_list,\n",
    "                                                        importances_list,\n",
    "                                                        view_str)\n",
    "        if inplace:\n",
    "            adata.uns[\"misty_results\"] = {\"target_metrics\": target_metrics,\n",
    "                                        \"importances\": importances\n",
    "                                        }\n",
    "        else:\n",
    "            return {\"target_metrics\": target_metrics,\n",
    "                    \"importances\": importances}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class Misty():\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liana-py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80a99255e5b17beb6f8c8dc403ec70687184f3f6557a2c5fe71e16aa6505930d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
