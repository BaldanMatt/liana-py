{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score: 0.09131650418520776\n",
      "Coefficients: [ 0.05876109  0.03658365 -0.11698    -0.11173144  0.0717869   0.12942832\n",
      " -0.06841139 -0.06184682 -0.01805924 -0.10640997]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# generate some sample data\n",
    "X = np.random.rand(100, 10)\n",
    "y = np.random.rand(100)\n",
    "\n",
    "# create a Ridge model and fit to the data\n",
    "ridge_model = Ridge(alpha=0.5)\n",
    "ridge_model.fit(X, y)\n",
    "\n",
    "# calculate the score and coefficients\n",
    "score = ridge_model.score(X, y)\n",
    "coefficients = ridge_model.coef_\n",
    "\n",
    "print(\"R^2 score:\", score)\n",
    "print(\"Coefficients:\", coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal value of alpha: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dbdimitrov/anaconda3/envs/liana-py/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Load data\n",
    "boston = load_boston()\n",
    "\n",
    "# Split data into features and target variable\n",
    "X, y = boston.data, boston.target\n",
    "\n",
    "# Initialize RidgeCV with the range of alpha values to test\n",
    "alphas = [0.1, 1.0, 10.0]\n",
    "ridge = RidgeCV(alphas=alphas)\n",
    "\n",
    "# Fit the model using cross-validation\n",
    "ridge.fit(X, y)\n",
    "\n",
    "# Print the optimal value of alpha\n",
    "print(\"Optimal value of alpha:\", ridge.alpha_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mRidgeCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0malphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgcv_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstore_cv_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0malpha_per_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Ridge regression with built-in cross-validation.\n",
      "\n",
      "See glossary entry for :term:`cross-validation estimator`.\n",
      "\n",
      "By default, it performs efficient Leave-One-Out Cross-Validation.\n",
      "\n",
      "Read more in the :ref:`User Guide <ridge_regression>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "alphas : ndarray of shape (n_alphas,), default=(0.1, 1.0, 10.0)\n",
      "    Array of alpha values to try.\n",
      "    Regularization strength; must be a positive float. Regularization\n",
      "    improves the conditioning of the problem and reduces the variance of\n",
      "    the estimates. Larger values specify stronger regularization.\n",
      "    Alpha corresponds to ``1 / (2C)`` in other linear models such as\n",
      "    :class:`~sklearn.linear_model.LogisticRegression` or\n",
      "    :class:`~sklearn.svm.LinearSVC`.\n",
      "    If using Leave-One-Out cross-validation, alphas must be positive.\n",
      "\n",
      "fit_intercept : bool, default=True\n",
      "    Whether to calculate the intercept for this model. If set\n",
      "    to false, no intercept will be used in calculations\n",
      "    (i.e. data is expected to be centered).\n",
      "\n",
      "normalize : bool, default=False\n",
      "    This parameter is ignored when ``fit_intercept`` is set to False.\n",
      "    If True, the regressors X will be normalized before regression by\n",
      "    subtracting the mean and dividing by the l2-norm.\n",
      "    If you wish to standardize, please use\n",
      "    :class:`~sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      "    on an estimator with ``normalize=False``.\n",
      "\n",
      "    .. deprecated:: 1.0\n",
      "        ``normalize`` was deprecated in version 1.0 and will be removed in\n",
      "        1.2.\n",
      "\n",
      "scoring : str, callable, default=None\n",
      "    A string (see model evaluation documentation) or\n",
      "    a scorer callable object / function with signature\n",
      "    ``scorer(estimator, X, y)``.\n",
      "    If None, the negative mean squared error if cv is 'auto' or None\n",
      "    (i.e. when using leave-one-out cross-validation), and r2 score\n",
      "    otherwise.\n",
      "\n",
      "cv : int, cross-validation generator or an iterable, default=None\n",
      "    Determines the cross-validation splitting strategy.\n",
      "    Possible inputs for cv are:\n",
      "\n",
      "    - None, to use the efficient Leave-One-Out cross-validation\n",
      "    - integer, to specify the number of folds.\n",
      "    - :term:`CV splitter`,\n",
      "    - An iterable yielding (train, test) splits as arrays of indices.\n",
      "\n",
      "    For integer/None inputs, if ``y`` is binary or multiclass,\n",
      "    :class:`~sklearn.model_selection.StratifiedKFold` is used, else,\n",
      "    :class:`~sklearn.model_selection.KFold` is used.\n",
      "\n",
      "    Refer :ref:`User Guide <cross_validation>` for the various\n",
      "    cross-validation strategies that can be used here.\n",
      "\n",
      "gcv_mode : {'auto', 'svd', 'eigen'}, default='auto'\n",
      "    Flag indicating which strategy to use when performing\n",
      "    Leave-One-Out Cross-Validation. Options are::\n",
      "\n",
      "        'auto' : use 'svd' if n_samples > n_features, otherwise use 'eigen'\n",
      "        'svd' : force use of singular value decomposition of X when X is\n",
      "            dense, eigenvalue decomposition of X^T.X when X is sparse.\n",
      "        'eigen' : force computation via eigendecomposition of X.X^T\n",
      "\n",
      "    The 'auto' mode is the default and is intended to pick the cheaper\n",
      "    option of the two depending on the shape of the training data.\n",
      "\n",
      "store_cv_values : bool, default=False\n",
      "    Flag indicating if the cross-validation values corresponding to\n",
      "    each alpha should be stored in the ``cv_values_`` attribute (see\n",
      "    below). This flag is only compatible with ``cv=None`` (i.e. using\n",
      "    Leave-One-Out Cross-Validation).\n",
      "\n",
      "alpha_per_target : bool, default=False\n",
      "    Flag indicating whether to optimize the alpha value (picked from the\n",
      "    `alphas` parameter list) for each target separately (for multi-output\n",
      "    settings: multiple prediction targets). When set to `True`, after\n",
      "    fitting, the `alpha_` attribute will contain a value for each target.\n",
      "    When set to `False`, a single alpha is used for all targets.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "cv_values_ : ndarray of shape (n_samples, n_alphas) or             shape (n_samples, n_targets, n_alphas), optional\n",
      "    Cross-validation values for each alpha (only available if\n",
      "    ``store_cv_values=True`` and ``cv=None``). After ``fit()`` has been\n",
      "    called, this attribute will contain the mean squared errors if\n",
      "    `scoring is None` otherwise it will contain standardized per point\n",
      "    prediction values.\n",
      "\n",
      "coef_ : ndarray of shape (n_features) or (n_targets, n_features)\n",
      "    Weight vector(s).\n",
      "\n",
      "intercept_ : float or ndarray of shape (n_targets,)\n",
      "    Independent term in decision function. Set to 0.0 if\n",
      "    ``fit_intercept = False``.\n",
      "\n",
      "alpha_ : float or ndarray of shape (n_targets,)\n",
      "    Estimated regularization parameter, or, if ``alpha_per_target=True``,\n",
      "    the estimated regularization parameter for each target.\n",
      "\n",
      "best_score_ : float or ndarray of shape (n_targets,)\n",
      "    Score of base estimator with best alpha, or, if\n",
      "    ``alpha_per_target=True``, a score for each target.\n",
      "\n",
      "    .. versionadded:: 0.23\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "See Also\n",
      "--------\n",
      "Ridge : Ridge regression.\n",
      "RidgeClassifier : Classifier based on ridge regression on {-1, 1} labels.\n",
      "RidgeClassifierCV : Ridge classifier with built-in cross validation.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.datasets import load_diabetes\n",
      ">>> from sklearn.linear_model import RidgeCV\n",
      ">>> X, y = load_diabetes(return_X_y=True)\n",
      ">>> clf = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1]).fit(X, y)\n",
      ">>> clf.score(X, y)\n",
      "0.5166...\n",
      "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/liana-py/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "?RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "liana-py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80a99255e5b17beb6f8c8dc403ec70687184f3f6557a2c5fe71e16aa6505930d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
